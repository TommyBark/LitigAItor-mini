{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/LitigAItor-mini-qNFIGzid/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainerCallback, Trainer, TrainingArguments, BitsAndBytesConfig\n",
    "from awq import AutoAWQForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from dataset import ConstantLengthDataset\n",
    "from tqdm import tqdm\n",
    "from contextlib import nullcontext\n",
    "from trl import SFTTrainer\n",
    "import os\n",
    "from huggingface_hub import HfApi\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"microsoft/Phi-3-mini-4k-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Quantizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_config, get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1, target_modules = \"all-linear\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 19 files: 100%|██████████| 19/19 [00:00<00:00, 70586.16it/s]\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]\n",
      "Downloading readme: 100%|██████████| 167/167 [00:00<00:00, 733kB/s]\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Downloading data: 100%|██████████| 471M/471M [00:05<00:00, 90.2MB/s] \n",
      "Generating validation split: 100%|██████████| 214670/214670 [00:21<00:00, 10002.73 examples/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8321 > 4096). Running this sequence through the model will result in indexing errors\n",
      "AWQ:   0%|          | 0/32 [00:00<?, ?it/s]WARNING:transformers_modules.c1358f8a35e6d2af81890deffbbfa575b978c62f.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
      "AWQ: 100%|██████████| 32/32 [16:00<00:00, 30.00s/it]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AwqConfig, AutoConfig\n",
    "# quant_path = model_path + \"-quant\"\n",
    "# quant_config = {\"zero_point\": True, \"q_group_size\": 128, \"w_bit\": 4, \"version\":\"GEMM\"}\n",
    "\n",
    "# # Load model\n",
    "# model = AutoAWQForCausalLM.from_pretrained(model_path)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "\n",
    "# # Quantize\n",
    "# model.quantize(tokenizer, quant_config=quant_config)\n",
    "\n",
    "\n",
    "# # modify the config file so that it is compatible with transformers integration\n",
    "# quantization_config = AwqConfig(\n",
    "#     bits=quant_config[\"w_bit\"],\n",
    "#     group_size=quant_config[\"q_group_size\"],\n",
    "#     zero_point=quant_config[\"zero_point\"],\n",
    "#     version=quant_config[\"version\"].lower(),\n",
    "# ).to_dict()\n",
    "\n",
    "# # the pretrained transformers model is stored in the model attribute + we need to pass a dict\n",
    "# model.model.config.quantization_config = quantization_config\n",
    "# # a second solution would be to use Autoconfig and push to hub (what we do at llm-awq)\n",
    "\n",
    "\n",
    "# # save model weights\n",
    "# model.save_quantized(quant_path)\n",
    "# tokenizer.save_pretrained(quant_path)\n",
    "# api = HfApi()\n",
    "# api.upload_folder(\n",
    "#     folder_path=quant_path,\n",
    "#     repo_id=\"TommyBark/Phi-3-mini-4k-instruct-awq\",\n",
    "#     repo_type=\"model\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.13s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path , trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path , trust_remote_code=True, quantization_config=bnb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 12,582,912 || all params: 3,833,662,464 || trainable%: 0.3282\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(model_path , trust_remote_code=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path , trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWQ Quantized - don't do this for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_model_path = \"TommyBark/Phi-3-mini-4k-instruct-awq\"\n",
    "local_model_path = \"./microsoft/Phi-3-mini-4k-instruct-quant/\"\n",
    "if os.path.exists(local_model_path):\n",
    "    model_path = local_model_path\n",
    "else:\n",
    "    model_path = hf_model_path\n",
    "    \n",
    "model = AutoAWQForCausalLM.from_quantized(model_path).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chars_token_ratio(dataset, tokenizer, nb_examples=200):\n",
    "    \"\"\"\n",
    "    Estimate the average number of characters per token in the dataset.\n",
    "    \"\"\"\n",
    "    total_characters, total_tokens = 0, 0\n",
    "    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n",
    "        text = example[\"document\"]\n",
    "        total_characters += len(text)\n",
    "        if tokenizer.is_fast:\n",
    "            total_tokens += len(tokenizer(text).tokens())\n",
    "        else:\n",
    "            total_tokens += len(tokenizer.tokenize(text))\n",
    "\n",
    "    return total_characters / total_tokens\n",
    "\n",
    "def create_datasets(tokenizer, dataset_name, split, streaming = True, seq_length = 1024,size_valid_set = 100):\n",
    "    dataset = load_dataset(\n",
    "        dataset_name,\n",
    "        split=split,\n",
    "        use_auth_token=True,\n",
    "        num_proc=None,\n",
    "        streaming=streaming,\n",
    "    )\n",
    "    if streaming:\n",
    "        shuffle_buffer = 4000\n",
    "        print(\"Loading the dataset in streaming mode\")\n",
    "        valid_data = dataset.take(size_valid_set)\n",
    "        train_data = dataset.skip(size_valid_set)\n",
    "        train_data = train_data.shuffle(buffer_size=shuffle_buffer, seed=None)\n",
    "    else:\n",
    "        dataset = dataset.train_test_split(test_size=0.005, seed=None)\n",
    "        train_data = dataset[\"train\"]\n",
    "        valid_data = dataset[\"test\"]\n",
    "        print(\n",
    "            f\"Size of the train set: {len(train_data)}. Size of the validation set: {len(valid_data)}\"\n",
    "        )\n",
    "\n",
    "    chars_per_token = chars_token_ratio(train_data, tokenizer)\n",
    "    print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n",
    "\n",
    "    train_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        train_data,\n",
    "        formatting_func=lambda x: x[\"document\"],\n",
    "        infinite=True,\n",
    "        seq_length=seq_length,\n",
    "        chars_per_token=chars_per_token,\n",
    "    )\n",
    "    valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        valid_data,\n",
    "        formatting_func=lambda x: x[\"document\"],\n",
    "        infinite=False,\n",
    "        seq_length=seq_length,\n",
    "        chars_per_token=chars_per_token,\n",
    "    )\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/LitigAItor-mini-qNFIGzid/lib/python3.10/site-packages/datasets/load.py:2554: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset in streaming mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:06<22:58,  6.93s/it]Token indices sequence length is longer than the specified maximum sequence length for this model (9045 > 4096). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 200/200 [00:08<00:00, 23.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The character to token ratio of the dataset is: 3.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ds = load_dataset(\"HFforLegal/case-law\",split='us', streaming=True)\n",
    "train_ds, eval_ds = create_datasets(tokenizer, \"HFforLegal/case-law\", \"us\", streaming=True, seq_length=1024, size_valid_set=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([29906,   501, 29889,  ...,  9245,   756,  2217], device='cuda:0'), 'labels': tensor([29906,   501, 29889,  ...,  9245,   756,  2217], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for i in eval_ds:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([ 1212,  2519, 29892,  ...,   342,   403,  2545], device='cuda:0'), 'labels': tensor([ 1212,  2519, 29892,  ...,   342,   403,  2545], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "for i in train_ds:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FinetuningArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./finetuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProfilerCallback(TrainerCallback):\n",
    "    def __init__(self, profiler):\n",
    "        self.profiler = profiler\n",
    "\n",
    "    def on_step_end(self, *args, **kwargs):\n",
    "        self.profiler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_profiler = True\n",
    "if enable_profiler:\n",
    "    wait, warmup, active, repeat = 1, 1, 2, 1\n",
    "    total_steps = (wait + warmup + active) * (1 + repeat)\n",
    "    schedule = torch.profiler.schedule(\n",
    "        wait=wait, warmup=warmup, active=active, repeat=repeat\n",
    "    )\n",
    "    profiler = torch.profiler.profile(\n",
    "        schedule=schedule,\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler(\n",
    "            f\"{output_dir}/logs/tensorboard\"\n",
    "        ),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True,\n",
    "        with_stack=True,\n",
    "    )\n",
    "\n",
    "    profiler_callback = ProfilerCallback(profiler)\n",
    "else:\n",
    "    profiler = nullcontext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_args = FinetuningArguments(model_name = model_path)\n",
    "peft_config = script_args.peft_config\n",
    "training_args = script_args.training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "training_config = {\n",
    "    \"bf16\": True,\n",
    "    \"do_eval\": False,\n",
    "    \"learning_rate\": 1.0e-04,\n",
    "    \"log_level\": \"info\",\n",
    "    \"logging_steps\": 100,\n",
    "    \"logging_strategy\": \"steps\",\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"output_dir\": \"./finetuning\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_eval_batch_size\": 2,\n",
    "    \"per_device_train_batch_size\": 3,\n",
    "    \"remove_unused_columns\": False,\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 3,\n",
    "    \"seed\": 0,\n",
    "    #    \"gradient_checkpointing\": True,\n",
    "    #    \"gradient_checkpointing_kwargs\":{\"use_reentrant\": False},\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"warmup_ratio\": 0.2,\n",
    "    \"report_to\": \"wandb\",\n",
    "    \"run_name\": \"ft-phi-3-mini-4k-instruct\",\n",
    "    \"max_steps\": 1500,\n",
    "}\n",
    "training_args = TrainingArguments(**training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with profiler:\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=eval_ds,\n",
    "        tokenizer=tokenizer,\n",
    "        args=training_args,\n",
    "        peft_config=peft_config,\n",
    "        callbacks=[profiler_callback] if enable_profiler else [],\n",
    "    )\n",
    "    trainer.train()\n",
    "\n",
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples: Unknown\n",
      "  Batch size = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.543197512626648,\n",
       " 'eval_runtime': 242.9595,\n",
       " 'eval_samples_per_second': 1.877,\n",
       " 'eval_steps_per_second': 1.877,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = tokenizer.decode(i[\"input_ids\"], skip_special_tokens=True, clean_up_tokenization_spaces=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"law, a trial court may consider in a postjudgment review of a\\njury's punitive-damages award. Factor 10, which is not listed in the\\ntext of the statute, is not a factor\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(trainer.model.generate(tokenizer(test_input[:100], return_tensors=\"pt\").to(device).input_ids, max_length=50), skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'law, a trial court may consider in a postjudgment review of a\\njury\\'s punitive-damages award. Factor number \"4\" is \"the\\nfinancial position of the defen'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input[:150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'law, a trial court may consider in a postjudgment '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input[:50] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoAWQForCausalLM.from_pretrained(output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The court held that\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_ids = model.to(device).generate(inputs.input_ids, max_length=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The court held that the defendant's actions were not protected under the First Amendment because they constituted a true threat, which is not a form of protected speech.\\n\\nStep 2: Understand the context of the case.\\nThe case involves a defendant who made statements that were interpreted as a threat. The court had to determine whether these statements were protected speech under the First Amendment or if they crossed the line into unprotected true threats.\\n\\nStep 3: Analyze the court's reasoning.\\nThe court's analysis focused on the nature of the statements made by the defendant. It considered whether the statements were made in a context that would lead a reasonable person to perceive them as a serious expression of intent to inflict harm.\\n\\nStep 4: Consider the precedent.\\nThe court referenced the precedent set in United States v. Alvarez, which established that the First Amendment does not protect speech that constitutes a true threat. This precedent is crucial in understanding the court's approach to the case at hand.\\n\\nStep 5: Evaluate the court's conclusion.\\nThe court concluded that the defendant's statements were not protected by the First Amendment because they were perceived as a true threat. The court found that the statements were made in a context that would lead a reasonable person to believe that the defendant intended to cause fear\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LitigAItor-mini-qNFIGzid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
